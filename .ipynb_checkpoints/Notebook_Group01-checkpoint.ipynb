{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# general\n",
    "import os\n",
    "import math\n",
    "import functools\n",
    "import itertools\n",
    "\n",
    "import pandas               as pd\n",
    "import numpy                as np\n",
    "import seaborn              as sns\n",
    "import matplotlib.pyplot    as plt\n",
    "import scipy.stats          as stats\n",
    "\n",
    "# preprocessing\n",
    "from sklearn.model_selection    import train_test_split\n",
    "from sklearn.model_selection    import StratifiedKFold\n",
    "from sklearn.model_selection    import learning_curve\n",
    "from sklearn.model_selection    import RandomizedSearchCV\n",
    "from sklearn.preprocessing      import OneHotEncoder\n",
    "from sklearn.preprocessing      import StandardScaler\n",
    "from sklearn.preprocessing      import MinMaxScaler\n",
    "from sklearn.preprocessing      import RobustScaler\n",
    "from sklearn.decomposition      import PCA\n",
    "from sklearn.feature_selection  import RFECV\n",
    "from sklearn.feature_selection  import SelectFromModel\n",
    "from sklearn.inspection         import permutation_importance\n",
    "from sklearn.pipeline           import Pipeline\n",
    "from sklearn.compose            import ColumnTransformer\n",
    "\n",
    "# classifier\n",
    "from sklearn.linear_model       import LogisticRegression\n",
    "from sklearn.linear_model       import SGDClassifier\n",
    "from sklearn.svm                import SVC\n",
    "from sklearn.neural_network     import MLPClassifier\n",
    "from sklearn.tree               import DecisionTreeClassifier\n",
    "from sklearn.ensemble           import RandomForestClassifier\n",
    "\n",
    "# metrics\n",
    "from sklearn.metrics            import f1_score\n",
    "from sklearn.model_selection    import cross_val_score\n",
    "from sklearn.metrics            import RocCurveDisplay\n",
    "from sklearn.metrics            import PrecisionRecallDisplay"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create dictionary with filename:data as key:value pairs\n",
    "data = {dataset_name.replace('.xlsx', ''): pd.read_excel(f'Data/{dataset_name}') for dataset_name in os.listdir('Data') if 'xlsx' in dataset_name}\n",
    "\n",
    "# merge train datasets on PatientID\n",
    "data_frames = [data['train_demo'], data['train_habits'], data['train_health']]\n",
    "df = functools.reduce(lambda  left,right: pd.merge(left,right,on=['PatientID'], how='outer'), data_frames).set_index('PatientID')\n",
    "\n",
    "# merge test datasets on PatientID\n",
    "data_frames = [data['test_demo'], data['test_habits'], data['test_health']]\n",
    "df_test = functools.reduce(lambda  left,right: pd.merge(left,right,on=['PatientID'], how='outer'), data_frames).set_index('PatientID')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# Exploratory Data Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# first look on the data\n",
    "df.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# list datatypes\n",
    "df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check for missing values and empty strings\n",
    "pd.concat([df.isnull().sum(),df.eq('').sum()],keys=['Nulls','Empty Strings'],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check for duplicated rows\n",
    "df.duplicated().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# descriptive statistics\n",
    "df.describe(include=\"all\").T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set()\n",
    "\n",
    "# plot pairwise relationships and densities\n",
    "sns.pairplot(df, hue = 'Disease', markers = ['o', 's'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# select numeric features (exclude target array)\n",
    "df_numeric_features = list(df.select_dtypes(include = np.number).columns)\n",
    "df_numeric_features.remove('Disease')\n",
    "\n",
    "# boxplot of numeric features\n",
    "fig, ax = plt.subplots(math.ceil(len(df_numeric_features)/4),4, figsize = (15,10))\n",
    "for ax, feat in zip(ax.flatten(), df_numeric_features):\n",
    "    ax.boxplot(df[feat], notch = True, patch_artist = True)\n",
    "    ax.set_title(feat)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# select categorical features (exclude name column)\n",
    "df_categorical_features = list(df.select_dtypes(exclude = np.number).columns)\n",
    "df_categorical_features.remove('Name')\n",
    "\n",
    "# stacked barplot of categorical features (with regard to target value)\n",
    "fig, ax = plt.subplots(len(df_categorical_features), figsize = (10,50))\n",
    "for ax, feat in zip(ax.flatten(), df_categorical_features):\n",
    "    pivot_tbl = df[[feat, 'Disease']].pivot_table(index = feat, columns = ['Disease'],  aggfunc=len)\n",
    "    graph = pivot_tbl.plot(kind='barh', stacked=True, title=feat, ax=ax)\n",
    "    ax.set_ylabel('')\n",
    "    for c in ax.containers:\n",
    "        ax.bar_label(c, label_type='center')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot gender distribution\n",
    "gender_imbalance = df.copy()\n",
    "gender_imbalance['Gender'] = ['Men' if i.split(' ')[0] == 'Mr.' else 'Women' for i in gender_imbalance.Name]\n",
    "pivot_tbl = gender_imbalance[['Gender', 'Disease']].pivot_table(index = 'Gender', columns = ['Disease'],  aggfunc=len)\n",
    "\n",
    "ax = pivot_tbl.plot(kind='bar', stacked=True, title='Gender Imbalance')\n",
    "\n",
    "for container in ax.containers:\n",
    "    ax.bar_label(container, label_type='center')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# Baseline Model\n",
    "\n",
    "- LogisticRegression with only numeric values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split to data & target\n",
    "x, y = df.drop(columns = ['Disease']), df['Disease']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# select numeric features\n",
    "initial_xnumeric = x.select_dtypes(include = np.number)\n",
    "initial_xnumeric_cols = initial_xnumeric.columns\n",
    "\n",
    "# stratified train-test split\n",
    "xtrain, xval, ytrain, yval = train_test_split(initial_xnumeric, y, random_state = 0 ,test_size = 0.2, shuffle = True , stratify = y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# very basic baseline model\n",
    "model = LogisticRegression(max_iter = 500, random_state = 1)\n",
    "model.fit(xtrain,ytrain)\n",
    "\n",
    "ypred = model.predict(xval)\n",
    "\n",
    "baseline_f1 = f1_score(yval, ypred)\n",
    "\n",
    "print(f'F1 score: {baseline_f1}')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocessing(dataframe):\n",
    "\n",
    "    # fix Birth_Year errors. here we assume that the outliers are typos\n",
    "    # the numbers 8 & 9 are pretty close to each other on a keyboard. therefore we add 100 to every year that's smaller than 1900\n",
    "    # (e.g. 1869 --> 1969)\n",
    "    dataframe['Birth_Year'] = [i + 100 if i < 1900 else i for i in dataframe['Birth_Year']]\n",
    "\n",
    "    # add Age column\n",
    "    dataframe['Age'] = [2022 - i for i in dataframe['Birth_Year']]\n",
    "\n",
    "    # add Gender column (1: Male, 0: Female)\n",
    "    # afterwards drop column Name\n",
    "    dataframe['Gender']  = [1 if i.split(' ')[0] == 'Mr.' else 0 for i in dataframe['Name']]\n",
    "    dataframe.drop(columns = ['Name'], inplace = True)\n",
    "\n",
    "    # add BMI columns\n",
    "    dataframe['BMI'] = [i/(j/100)**2 for i, j in zip(dataframe['Weight'], dataframe['Height'])]\n",
    "    dataframe['BMI_Cateogry'] = [0 if i < 18.5 else 1 if i < 25 else 2 if i < 30 else 3 if i < 35 else 4 for i in dataframe['BMI']]\n",
    "\n",
    "    # set all region values to lowercase\n",
    "    dataframe['Region'] = [i.lower() for i in dataframe['Region']]\n",
    "\n",
    "    # handle High_Cholesterol, Blood_Pressure, Physical_Health\n",
    "    # flooring and capping outliers\n",
    "    for col in ['High_Cholesterol', 'Blood_Pressure', 'Physical_Health']:\n",
    "        q25, q75, iqr = dataframe[col].quantile(.25), dataframe[col].quantile(.75), dataframe[col].quantile(.75) - dataframe[col].quantile(.25)\n",
    "        upper_lim = q75 + 1.5 * iqr\n",
    "        lower_lim = q25 - 1.5 * iqr\n",
    "        dataframe[col] = [upper_lim if i > upper_lim else lower_lim if i < lower_lim else i for i in dataframe[col]]\n",
    "\n",
    "    # encode Smoking_Habit & Exercise to binary (1: Yes, 0: No)\n",
    "    dataframe['Smoking_Habit'] = [1 if i == 'Yes' else 0 for i in dataframe['Smoking_Habit']]\n",
    "    dataframe['Exercise'] = [1 if i == 'Yes' else 0 for i in dataframe['Exercise']]    \n",
    "    \n",
    "    # manual encoding of specific feature to don't mess up the ranking\n",
    "    # all of these features have a specific ranking structure\n",
    "    # another advantage is the avoidance of dimensionality increase through One-hot-encoding all categorical features\n",
    "\n",
    "    # impute missing values in column \"Education\" with mode\n",
    "    # encode Education\n",
    "    dataframe['Education'].fillna(dataframe['Education'].mode()[0], inplace=True)\n",
    "    edu_map = {\n",
    "            'I never attended school / Other'               : 0,\n",
    "            'Elementary School (1st to 9th grade)'          : 1,\n",
    "            'High School Incomplete (10th to 11th grade)'   : 2,\n",
    "            'High School Graduate'                          : 3,\n",
    "            'University Incomplete (1 to 2 years)'          : 4,\n",
    "            'University Complete (3 or more years)'         : 5\n",
    "            }\n",
    "    dataframe['Education'] = [edu_map[i] if i in edu_map.keys() else np.nan for i in dataframe['Education']]\n",
    "\n",
    "    drink_map = {\n",
    "            'I do not consume any type of alcohol'          : 0,\n",
    "            'I consider myself a social drinker'            : 1,\n",
    "            'I usually consume alcohol every day'           : 2\n",
    "            }\n",
    "    dataframe['Drinking_Habit'] = [drink_map[i] if i in drink_map.keys() else np.nan for i in dataframe['Drinking_Habit']]\n",
    "\n",
    "    fruit_map = {\n",
    "            'Less than 1. I do not consume fruits every day.'   : 0,\n",
    "            '1 to 2 pieces of fruit in average'                 : 1,\n",
    "            '3 to 4 pieces of fruit in average'                 : 2,\n",
    "            '5 to 6 pieces of fruit in average'                 : 3,\n",
    "            'More than six pieces of fruit'                     : 4\n",
    "            }\n",
    "    dataframe['Fruit_Habit'] = [fruit_map[i] if i in fruit_map.keys() else np.nan for i in dataframe['Fruit_Habit']]\n",
    "\n",
    "    water_map = {\n",
    "            'Less than half a liter'                            : 0,\n",
    "            'More than half a liter but less than one liter'    : 1,\n",
    "            'Between one liter and two liters'                  : 2\n",
    "            }\n",
    "    dataframe['Water_Habit'] = [water_map[i] if i in water_map.keys() else np.nan for i in dataframe['Water_Habit']]\n",
    "\n",
    "    checkup_map = {\n",
    "            'Not sure'                                          : 0,\n",
    "            'More than 3 years'                                 : 1,\n",
    "            'Less than 3 years but more than 1 year'            : 2,\n",
    "            'Less than three months'                            : 3\n",
    "            }\n",
    "    dataframe['Checkup'] = [checkup_map[i] if i in checkup_map.keys() else np.nan for i in dataframe['Checkup']]\n",
    "\n",
    "    diabetes_map = {\n",
    "            'I do have diabetes'                                                            : 0,\n",
    "            'I have/had pregnancy diabetes or borderline diabetes'                          : 1,\n",
    "            \"I don't have diabetes, but I have direct family members who have diabetes.\"    : 2,\n",
    "            'Neither I nor my immediate family have diabetes.'                              : 3\n",
    "            }\n",
    "    dataframe['Diabetes'] = [diabetes_map[i] if i in diabetes_map.keys() else np.nan for i in dataframe['Diabetes']]\n",
    "\n",
    "    return dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# apply preprocessing steps to x\n",
    "x_preprocessed = preprocessing(x.copy())"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# Check Different Scaler Options"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# scaler options\n",
    "scalers = [StandardScaler(), MinMaxScaler(), MinMaxScaler(feature_range = (-1,1)), RobustScaler()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_scaler_encoder(X,Y,scaler_options,classifier):\n",
    "\n",
    "        ranking = {'scaler':[],'score':[]}\n",
    "\n",
    "        # create crossvalidation splits\n",
    "        skf = StratifiedKFold(shuffle=True, random_state = 0)\n",
    "\n",
    "        for scl in scaler_options:\n",
    "\n",
    "                # scores list for every k-fold f1-score\n",
    "                scores = []\n",
    "\n",
    "                # calculate f1-score for each train-test split with the given scaler\n",
    "                for train_index, val_index in skf.split(X, Y):\n",
    "                        X_train, X_val = X.iloc[train_index], X.iloc[val_index]\n",
    "                        y_train, y_val = Y.iloc[train_index], Y.iloc[val_index]\n",
    "\n",
    "                        numeric_features, categorical_features = X_train.select_dtypes(include = np.number).columns, X_train.select_dtypes(exclude = np.number).columns\n",
    "\n",
    "                        numeric_transformer = Pipeline(steps=[\n",
    "                                ('scaler', scl)\n",
    "                                ])\n",
    "\n",
    "                        categorical_transformer = Pipeline(steps=[\n",
    "                                ('encoder', OneHotEncoder(handle_unknown='ignore'))\n",
    "                                ])\n",
    "\n",
    "                        preprocessor = ColumnTransformer(transformers=[\n",
    "                                ('cat', categorical_transformer, categorical_features),\n",
    "                                ('num', numeric_transformer, numeric_features)\n",
    "                                ])\n",
    "\n",
    "                        model = Pipeline(steps=[\n",
    "                                (\"preprocessor\", preprocessor),\n",
    "                                (\"classifier\", classifier)\n",
    "                                ])\n",
    "                        \n",
    "                        model.fit(X_train, y_train)\n",
    "                        # add every score to the previously created scores list\n",
    "                        scores.append(round(f1_score(y_val, model.predict(X_val)),4))\n",
    "\n",
    "                # add scaler and cross validated mean of scores list to dictionary\n",
    "                ranking['scaler'].append(scl)\n",
    "                ranking['score'].append(np.mean(scores))\n",
    "\n",
    "        # returns dataframe with the cross validated scores for each scaler\n",
    "        return pd.DataFrame(ranking).sort_values('score', ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_scaler_encoder(x_preprocessed, y, scalers, LogisticRegression(max_iter=500, random_state=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_scaler_encoder(x_preprocessed, y, scalers, SGDClassifier(random_state=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_scaler_encoder(x_preprocessed, y, scalers, SVC(random_state=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_scaler_encoder(x_preprocessed, y, scalers, MLPClassifier(max_iter=1500, random_state=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_scaler_encoder(x_preprocessed, y, scalers, DecisionTreeClassifier(random_state=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_scaler_encoder(x_preprocessed, y, scalers, RandomForestClassifier(random_state=1))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# Train/Test Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# again a stratified train-test split with the same random_state as before\n",
    "xtrain, xval, ytrain, yval = train_test_split(x_preprocessed, y, random_state = 0 ,test_size = 0.2, shuffle = True , stratify = y)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# Prepare Train/Test Split (One-Hot-Encode, Scale) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def encode_scale(dataframe, reset_fit=False):\n",
    "\n",
    "    '''\n",
    "    One-hot-encode and scales dataframe\n",
    "    If reset_fit set to TRUE encoder & scaler get refitted\n",
    "    '''\n",
    "\n",
    "    # fit_transform if no scaler and one-hot-encoder is already fitted\n",
    "    if not('ohe' in globals() and 'scl' in globals()) or reset_fit == True:\n",
    "        xnumeric, xcategorical = dataframe.select_dtypes(include = np.number), dataframe.select_dtypes(exclude = np.number)\n",
    "        # One-hot-encoding\n",
    "        # set encoder to global variable to re-use it afterwards\n",
    "        global ohe\n",
    "        ohe = OneHotEncoder(handle_unknown='ignore')\n",
    "        categorical_encoded = pd.DataFrame(ohe.fit_transform(xcategorical).toarray(), columns = ohe.get_feature_names_out(), index = xcategorical.index)\n",
    "        dataframe_encoded = pd.concat([xnumeric, categorical_encoded], axis = 1)\n",
    "        # Robust-scaling\n",
    "        # set scaler to global variable to re-use it afterwards\n",
    "        global scl\n",
    "        scl = RobustScaler()\n",
    "        dataframe_scaled = pd.DataFrame(scl.fit_transform(dataframe_encoded), columns = dataframe_encoded.columns, index = dataframe_encoded.index)\n",
    "        print('fit & transform successful...')\n",
    "        return dataframe_scaled\n",
    "\n",
    "    # transform only if scaler and one-hot-encoder is already fitted\n",
    "    else:\n",
    "        xnumeric, xcategorical = dataframe.select_dtypes(include = np.number), dataframe.select_dtypes(exclude = np.number)\n",
    "        # One-hot-encoding\n",
    "        categorical_encoded = pd.DataFrame(ohe.transform(xcategorical).toarray(), columns = ohe.get_feature_names_out(), index = xcategorical.index)\n",
    "        dataframe_encoded = pd.concat([xnumeric, categorical_encoded], axis = 1)\n",
    "        #Robust-scaling\n",
    "        dataframe_scaled = pd.DataFrame(scl.transform(dataframe_encoded), columns = dataframe_encoded.columns, index = dataframe_encoded.index)\n",
    "\n",
    "        print('transform successful...')\n",
    "        return dataframe_scaled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# apply encoding and scaling function on xtrain (fit & transform)\n",
    "xtrain_prepro = encode_scale(xtrain, reset_fit=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# apply encoding and scaling function on xtrain (only transform)\n",
    "xval_prepro = encode_scale(xval)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def principal_component_analysis(dataframe, var_treshold=0.8, reset_fit=False):\n",
    "    '''\n",
    "    Creates and add n principal components (dependent on variance treshold)\n",
    "    '''\n",
    "\n",
    "    # fit_transform if pca isn't already fitted\n",
    "    if not 'pca' in globals() or reset_fit == True:\n",
    "        # set 'pca' to global variable to re-use it afterwards\n",
    "        global pca\n",
    "        pca = PCA(n_components=var_treshold)\n",
    "        pca_feat = pca.fit_transform(dataframe)\n",
    "        pca_feat_names = [f'PC{i}' for i in range(pca.n_components_)]\n",
    "        pca_df = pd.DataFrame(pca_feat, index=dataframe.index, columns=pca_feat_names)\n",
    "        dataframe = pd.concat([dataframe, pca_df], axis=1)\n",
    "        print('fit & transform successful...')\n",
    "        return dataframe\n",
    "    \n",
    "    # transform only if pca is already fitted\n",
    "    else:\n",
    "        pca_feat = pca.transform(dataframe)\n",
    "        pca_feat_names = [f'PC{i}' for i in range(pca.n_components_)]\n",
    "        pca_df = pd.DataFrame(pca_feat, index=dataframe.index, columns=pca_feat_names)\n",
    "        dataframe = pd.concat([dataframe, pca_df], axis=1)\n",
    "        print('transform successful...')\n",
    "        return dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add pca features to xtrain (fit & transform)\n",
    "xtrain_pca = principal_component_analysis(xtrain_prepro)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add pca features to xval (only transform)\n",
    "xval_pca = principal_component_analysis(xval_prepro)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# Feature Selection - Filter Methods"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Correlation Matrix (Spearman)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cor_heatmap(cor):\n",
    "    plt.figure(figsize=(10,7))\n",
    "    sns.heatmap(data = cor, annot = True, cmap = plt.cm.Reds, fmt='.2')\n",
    "    plt.show()\n",
    "\n",
    "cor_spearman = cor_heatmap(xtrain_prepro[initial_xnumeric_cols].corr(\"spearman\"))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Chi-squared"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def TestIndependence(X,Y,var,alpha=0.05):\n",
    "    CRED = '\\033[91m'\n",
    "    CGREEN = '\\033[92m'\n",
    "    CEND = '\\033[0m'   \n",
    "    dfObserved = pd.crosstab(Y,X) \n",
    "    chi2, p, dof, expected = stats.chi2_contingency(dfObserved.values)\n",
    "    dfExpected = pd.DataFrame(expected, columns=dfObserved.columns, index = dfObserved.index)\n",
    "    if p<alpha:\n",
    "        result= str(var) + CGREEN + ' IMPORTANT' + CEND\n",
    "    else:\n",
    "        result= str(var) + CRED + ' NOT IMPORTANT' + CEND\n",
    "    print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "initial_xcategorical_col = [i for i in x.columns if i not in initial_xnumeric_cols]\n",
    "initial_xcategorical_col.remove('Name')\n",
    "initial_xcategorical_col.remove('Region')\n",
    "\n",
    "for var in initial_xcategorical_col:\n",
    "    TestIndependence(xtrain_prepro[var],ytrain, var)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Selection - Wrapper Methods"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Recursive Feature Elimination (RFE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = RandomForestClassifier(random_state = 1)\n",
    "rfe = RFECV(model, cv = 5, scoring = 'f1', n_jobs = -1)\n",
    "rfe.fit(xtrain_prepro, ytrain)\n",
    "opt_features = list(rfe.get_feature_names_out(input_features = list(xtrain_prepro.columns)))\n",
    "print(f'Best features: {[i for i in opt_features]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# transform data to RFE results\n",
    "xtrain_rfe = rfe.transform(xtrain_prepro)\n",
    "xval_rfe = rfe.transform(xval_prepro)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Selection - Embedded Method"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Select From Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# embedded feature selection with SelectFromModel and RandomForestClassifier\n",
    "sfm = SelectFromModel(RandomForestClassifier(random_state = 1))\n",
    "sfm.fit(xtrain_prepro, ytrain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check columns\n",
    "selected_feat = xtrain_prepro.columns[(sfm.get_support())]\n",
    "selected_feat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# transform data to SelectFromModel results\n",
    "xtrain_sfm = pd.DataFrame(sfm.transform(xtrain_prepro), columns=xtrain_prepro.columns[(sfm.get_support())], index=xtrain_prepro.index)\n",
    "xval_sfm = pd.DataFrame(sfm.transform(xval_prepro), columns=xval_prepro.columns[(sfm.get_support())], index=xval_prepro.index)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# Model Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifiers = {\n",
    "                'Logistic Regression': LogisticRegression(),\n",
    "                'Support Vector Machine': SVC(),\n",
    "                'Stochastic Gradient Descent': SGDClassifier(),\n",
    "                'Neural Network': MLPClassifier(max_iter = 1500),\n",
    "                'Decision Tree': DecisionTreeClassifier(),\n",
    "                'Random Forest': RandomForestClassifier()\n",
    "                }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def roc_auc(classifiers, xtrain, ytrain, xval, yval):\n",
    "    '''\n",
    "    Plots ROC/AUC\n",
    "    classifiers input --> {'Logistic Regression': LogisticRegression(),...}\n",
    "    '''\n",
    "\n",
    "    fig, ax = plt.subplots(1, figsize=(15, 10))\n",
    "    for name, clf in classifiers.items():\n",
    "        clf.fit(xtrain, ytrain)\n",
    "        RocCurveDisplay.from_estimator(clf, xval, yval, ax=ax, name=name)\n",
    "    ax.set_title('ROC/AUC Curve')\n",
    "    ax.plot([0,1], [0,1], linestyle='--')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prec_rec(classifiers, xtrain, ytrain, xval, yval):\n",
    "    '''\n",
    "    Plots Precision/Recall Curve\n",
    "    classifiers input --> {'Logistic Regression': LogisticRegression(),...}\n",
    "    '''\n",
    "\n",
    "    fig, ax = plt.subplots(1, figsize=(15, 10))\n",
    "    for name, clf in classifiers.items():\n",
    "        clf.fit(xtrain, ytrain)\n",
    "        PrecisionRecallDisplay.from_estimator(clf, xval, yval, ax=ax, name=name)\n",
    "    ax.set_title('Precision/Recall Curve')\n",
    "    ax.plot([0,1], [1,0], linestyle='--')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def learning_curves(estimator, X, Y):\n",
    "    '''\n",
    "    Plots cross validated learning curve\n",
    "    '''\n",
    "\n",
    "    train_sizes, train_scores, validation_scores = learning_curve(estimator, X, Y, cv = 5, scoring = 'f1', train_sizes = np.arange(.05,1,.05))\n",
    "    train_mean, test_mean, train_std, test_std = np.mean(train_scores, axis=1), np.mean(validation_scores, axis=1), np.std(train_scores, axis=1), np.std(validation_scores, axis=1)\n",
    "\n",
    "    plt.subplots(1, figsize=(10,10))\n",
    "    plt.plot(train_sizes, train_mean, color='salmon',  label='Training score', marker = 'o')\n",
    "    plt.plot(train_sizes, test_mean, color='olive', label='Cross-validation score', marker = 's')\n",
    "    plt.title('Learning Curve')\n",
    "    plt.xlabel('Training Set Size')\n",
    "    plt.ylabel('F1 Score')\n",
    "    plt.legend(loc='best')\n",
    "    plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ROC/AUC Curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "roc_auc(classifiers, xtrain_sfm, ytrain, xval_sfm, yval)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Precision/Recall Curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prec_rec(classifiers, xtrain_sfm, ytrain, xval_sfm, yval)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# Model Optimization"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## Stochastic Gradient Descent (SGDClassifier) - Optimizing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# feature selection with SelectFromModel (SGDClassifier)\n",
    "sfm = SelectFromModel(SGDClassifier(random_state = 1))\n",
    "sfm.fit(xtrain_prepro, ytrain)\n",
    "\n",
    "xtrain_sfm = pd.DataFrame(sfm.transform(xtrain_prepro), columns=xtrain_prepro.columns[(sfm.get_support())], index=xtrain_prepro.index)\n",
    "xval_sfm = pd.DataFrame(sfm.transform(xval_prepro), columns=xval_prepro.columns[(sfm.get_support())], index=xval_prepro.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get first score of model\n",
    "model = SGDClassifier(random_state = 1)\n",
    "model.fit(xtrain_sfm, ytrain)\n",
    "\n",
    "ypred = model.predict(xval_sfm)\n",
    "\n",
    "print(f'F1 Score: {f1_score(yval, ypred)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# checking the learning curve for over-fitting\n",
    "learning_curves(SGDClassifier(random_state=1), xtrain_sfm, ytrain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# performing hyperparameter tuning\n",
    "param_grid = {\n",
    "    'loss': ['hinge', 'log', 'modified_huber', 'squared_hinge', 'perceptron'],\n",
    "    'penalty': ['none', 'l2', 'l1', 'elasticnet'],\n",
    "    'alpha': [0.0001, 0.001, 0.01, 0.1],\n",
    "    'l1_ratio': [0, 0.15, 0.5, 0.85, 1]\n",
    "}\n",
    "\n",
    "model = SGDClassifier(random_state = 1)\n",
    "rand_search = RandomizedSearchCV(estimator = model, param_distributions = param_grid, scoring = 'f1', n_iter = 100, cv = 3, random_state=3, n_jobs = -1)\n",
    "rand_search.fit(xtrain_sfm, ytrain)\n",
    "\n",
    "print(str(rand_search.best_params_).replace('{','').replace('}','').replace(\"'\",\"\").replace(':','='))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check learning curve again\n",
    "learning_curves(SGDClassifier(**rand_search.best_params_, random_state=1), xtrain_sfm, ytrain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get final score with tuned hyperparameters\n",
    "model = SGDClassifier(**rand_search.best_params_, random_state = 1)\n",
    "model.fit(xtrain_sfm, ytrain)\n",
    "\n",
    "ypred = model.predict(xval_sfm)\n",
    "\n",
    "print(f'F1 Score: {f1_score(yval, ypred)}')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Neural Network - Optimizing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# feature selection with permutation_importance (MLPClassifier)\n",
    "model = MLPClassifier(max_iter=1500, random_state=1)\n",
    "model.fit(xtrain_prepro, ytrain)\n",
    "\n",
    "permutation_score = permutation_importance(model, xtrain_prepro, ytrain, n_repeats=10) \n",
    "\n",
    "# returns dataframe sorted by permutation score\n",
    "importance_df = pd.DataFrame(np.vstack((xtrain_prepro.columns, permutation_score.importances_mean)).T, columns=['Feature', 'Score']) \n",
    "importance_df = importance_df.sort_values('Score', ascending = False).reset_index(drop=True)\n",
    "importance_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check which n-best features result in the best cross validated score\n",
    "results = {'Feature Combination':[],'AVG Score':[]}\n",
    "for i in range(0,len(importance_df)+1):\n",
    "    features = list(importance_df.Feature.loc[0:i])\n",
    "    avg_score = np.mean(cross_val_score(MLPClassifier(max_iter=2000, random_state=1), xtrain_prepro[features], ytrain, cv=3))\n",
    "    results['Feature Combination'].append(features)\n",
    "    results['AVG Score'].append(avg_score)\n",
    "\n",
    "feature_comb_scores = pd.DataFrame(results)\n",
    "best_comb = feature_comb_scores.sort_values('AVG Score', ascending=False).iloc[0]['Feature Combination']\n",
    "\n",
    "feature_comb_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop other features\n",
    "xtrain_permut = xtrain_prepro[best_comb]\n",
    "xval_permut = xval_prepro[best_comb]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get first score of model\n",
    "model = MLPClassifier(max_iter = 1500, random_state = 1)\n",
    "model.fit(xtrain_permut, ytrain)\n",
    "\n",
    "ypred = model.predict(xval_permut)\n",
    "\n",
    "print(f'F1 Score: {f1_score(yval, ypred)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# checking the learning curve for over-fitting\n",
    "learning_curves(MLPClassifier(max_iter = 1500, random_state = 1), xtrain_permut, ytrain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# performing hyperparameter tuning\n",
    "param_grid = {\n",
    "    'activation': ['identity', 'logistic', 'tanh', 'relu'],\n",
    "    'solver': ['sgd', 'adam'],\n",
    "    'alpha': [0.0001, 0.001, 0.005, 0.01, 0.05, 0.1],\n",
    "    'learning_rate': ['constant', 'invscaling', 'adaptive']\n",
    "}\n",
    "\n",
    "model = MLPClassifier(max_iter=1500, random_state=1)\n",
    "rand_search = RandomizedSearchCV(estimator = model, param_distributions = param_grid, scoring = 'f1', n_iter = 100, cv = 3, random_state=3, n_jobs = -1)\n",
    "rand_search.fit(xtrain_permut, ytrain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print best paramater combinations\n",
    "print(str(rand_search.best_params_).replace('{','').replace('}','').replace(\"'\",\"\").replace(':','='))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check learning curve again\n",
    "learning_curves(MLPClassifier(max_iter=1500 , **rand_search.best_params_, random_state=1), xtrain_permut, ytrain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get final score with tuned hyperparameters\n",
    "model = MLPClassifier(max_iter=1500, **rand_search.best_params_, random_state=1)\n",
    "model.fit(xtrain_permut, ytrain)\n",
    "\n",
    "ypred = model.predict(xval_permut)\n",
    "\n",
    "print(f'F1 Score: {f1_score(yval, ypred)}')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Decision Tree - Optimizing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# feature selection with SelectFromModel (DecisionTreeClassifier)\n",
    "sfm = SelectFromModel(DecisionTreeClassifier(random_state = 1))\n",
    "sfm.fit(xtrain_prepro, ytrain)\n",
    "\n",
    "xtrain_sfm = pd.DataFrame(sfm.transform(xtrain_prepro), columns=xtrain_prepro.columns[(sfm.get_support())], index=xtrain_prepro.index)\n",
    "xval_sfm = pd.DataFrame(sfm.transform(xval_prepro), columns=xval_prepro.columns[(sfm.get_support())], index=xval_prepro.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get first score of model\n",
    "model = DecisionTreeClassifier(random_state = 1)\n",
    "model.fit(xtrain_sfm, ytrain)\n",
    "\n",
    "ypred = model.predict(xval_sfm)\n",
    "\n",
    "print(f'F1 Score: {f1_score(yval, ypred)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# checking the learning curve for over-fitting\n",
    "learning_curves(DecisionTreeClassifier(random_state=1), xtrain_sfm, ytrain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# performing hyperparameter tuning\n",
    "param_grid = {\n",
    "    'max_depth': [5, 10, 15, 20, 25],\n",
    "    'min_samples_split': [2, 5, 10],\n",
    "    'min_samples_leaf': [1, 2, 3],\n",
    "    'max_features': ['sqrt', 'log2', None]\n",
    "}\n",
    "\n",
    "\n",
    "model = DecisionTreeClassifier(random_state = 1)\n",
    "rand_search = RandomizedSearchCV(estimator = model, param_distributions = param_grid, scoring = 'f1', n_iter = 100, cv = 3, random_state=3, n_jobs = -1)\n",
    "rand_search.fit(xtrain_sfm, ytrain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print best paramater combinations\n",
    "print(str(rand_search.best_params_).replace('{','').replace('}','').replace(\"'\",\"\").replace(':','='))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check learning curve again\n",
    "learning_curves(DecisionTreeClassifier(**rand_search.best_params_, random_state=1), xtrain_sfm, ytrain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get final score with tuned hyperparameters\n",
    "model = DecisionTreeClassifier(**rand_search.best_params_, random_state = 1)\n",
    "model.fit(xtrain_sfm, ytrain)\n",
    "\n",
    "ypred = model.predict(xval_sfm)\n",
    "\n",
    "print(f'F1 Score: {f1_score(yval, ypred)}')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Random Forest - Optimizing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# feature selection with SelectFromModel (RandomForestClassifier)\n",
    "sfm = SelectFromModel(RandomForestClassifier(random_state = 1))\n",
    "sfm.fit(xtrain_prepro, ytrain)\n",
    "\n",
    "xtrain_sfm = pd.DataFrame(sfm.transform(xtrain_prepro), columns=xtrain_prepro.columns[(sfm.get_support())], index=xtrain_prepro.index)\n",
    "xval_sfm = pd.DataFrame(sfm.transform(xval_prepro), columns=xval_prepro.columns[(sfm.get_support())], index=xval_prepro.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get first score of model\n",
    "model = RandomForestClassifier(random_state = 1)\n",
    "model.fit(xtrain_sfm, ytrain)\n",
    "\n",
    "ypred = model.predict(xval_sfm)\n",
    "\n",
    "print(f'F1 Score: {f1_score(yval, ypred)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# checking the learning curve for over-fitting\n",
    "learning_curves(RandomForestClassifier(random_state = 1), xtrain_sfm, ytrain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# performing hyperparameter tuning\n",
    "param_grid = {\n",
    "    'n_estimators': [100, 200, 300, 400, 500],\n",
    "    'max_depth': [5, 10, 15, 20, 25],\n",
    "    'min_samples_split': [2, 5, 10],\n",
    "    'min_samples_leaf': [1, 2, 3],\n",
    "    'max_features': ['sqrt', 'log2', None]\n",
    "}\n",
    "\n",
    "model = RandomForestClassifier(random_state = 1)\n",
    "rand_search = RandomizedSearchCV(estimator = model, param_distributions = param_grid, scoring = 'f1', n_iter = 100, cv = 3, random_state=3, n_jobs = -1)\n",
    "rand_search.fit(xtrain_sfm, ytrain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print best paramater combinations\n",
    "print(str(rand_search.best_params_).replace('{','').replace('}','').replace(\"'\",\"\").replace(':','='))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check learning curve again\n",
    "learning_curves(RandomForestClassifier(**rand_search.best_params_, random_state=1), xtrain_sfm, ytrain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get final score with tuned hyperparameters\n",
    "model = RandomForestClassifier(**rand_search.best_params_, random_state = 1)\n",
    "model.fit(xtrain_sfm, ytrain)\n",
    "\n",
    "ypred = model.predict(xval_sfm)\n",
    "\n",
    "print(f'F1 score: {f1_score(yval, ypred)}')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# Submission "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**1** - Train on full dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# apply encoding & scaling\n",
    "# reset_fit set to True for new fit_transform (including all train observations)\n",
    "xtrain_prepro_full = encode_scale(preprocessing(x), reset_fit = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# apply feature selection on full train dataset\n",
    "xtrain_sfm_full = sfm.transform(xtrain_prepro_full)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fit model with best hyperparameters\n",
    "model = RandomForestClassifier(**rand_search.best_params_, random_state = 1)\n",
    "model.fit(xtrain_sfm_full, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**2** - Prepare test dataset and predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# apply preprocessing function and encode_scale function to test dataset\n",
    "xtest_prepro = encode_scale(preprocessing(df_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# transform data to SelectFromModel\n",
    "xtest_sfm = sfm.transform(xtest_prepro)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# final predict\n",
    "ypred = model.predict(xtest_sfm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_submission = pd.concat([pd.Series(df_test.index),pd.Series(ypred)], axis = 1)\n",
    "df_submission.rename(columns = {0:'Disease'}, inplace = True)\n",
    "df_submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_submission.to_csv('Group01_Final_RandomForest.csv', index = False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "1335a209088fba08ed1ec7ee6e9c6b845cf55524ee893ab338ddd70a4ed03024"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
